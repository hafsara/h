Top, ta proposition va dans le bon sens. Voici ce que je te recommande pour qu‚Äôelle soit **propre, idempotente et 100% actif-actif**, avec des corrections concr√®tes sur ton code actuel.

---

# 0) Les 4 points cl√©s (r√©sum√©)

1. **Workers Celery en parall√®le** : OK, mets `worker_prefetch_multiplier=1` + `task_acks_late=True` pour √©viter les doublons apr√®s crash.
2. **Beat unique ou distribu√©** : un seul Beat, ou RedBeat si tu veux la tol√©rance de panne du scheduler.
3. **DB** : continue √† utiliser `FOR UPDATE SKIP LOCKED` et marque *imm√©diatement* le step ‚Äúprocessing‚Äù sous transaction.
4. **App context Flask** : garde une Task Celery qui pousse le contexte Flask (sinon mails/DB plantent parfois).

---

# 1) `workflow/celery_app.py` ‚Äî version actif-actif (corrig√©e + compl√®te)

```python
# workflow/celery_app.py
from datetime import timedelta
import logging
from celery import Celery
from kombu import Queue, Exchange
from celery.signals import worker_ready, worker_shutdown
from config import Config
from api.app import create_app

logger = logging.getLogger(__name__)

def make_celery(flask_app):
    celery_app = Celery(
        __name__,
        broker=Config.CELERY_BROKER_URL,
        backend=Config.CELERY_RESULT_BACKEND,
        enable_utc=True,
    )

    # ---- HA & scaling horizontal
    celery_app.conf.update(
        # Fiabilit√©
        task_acks_late=True,                 # si le worker meurt, la t√¢che est re-queue
        worker_prefetch_multiplier=1,        # √©vite qu‚Äôun worker ‚Äúaspire‚Äù trop de t√¢ches
        task_time_limit=300,                 # tue les tasks coinc√©es
        task_soft_time_limit=270,

        # Broker r√©silient
        broker_connection_retry_on_startup=True,
        broker_connection_retry=True,
        broker_connection_max_retries=100,

        # S√©rialisation
        task_serializer='json',
        result_serializer='json',
        accept_content=['json'],
        result_expires=timedelta(hours=6),

        # Events (monitoring Flower/Prometheus exporter)
        worker_send_task_events=True,
        task_send_sent_event=True,
    )

    # ---- Files d‚Äôattente
    default_ex = Exchange('default', type='direct')
    beat_ex = Exchange('beat', type='direct')
    high_ex = Exchange('high_priority', type='direct')

    celery_app.conf.task_queues = (
        Queue('high_priority', high_ex, routing_key='high_priority',
              queue_arguments={'x-max-priority': 10}),
        Queue('beat_tasks', beat_ex, routing_key='beat.process'),
        Queue('default', default_ex, routing_key='default'),
    )

    celery_app.conf.task_default_queue = 'default'
    celery_app.conf.task_default_exchange = 'default'
    celery_app.conf.task_default_routing_key = 'default'

    celery_app.conf.task_routes = {
        'workflow.tasks.core.scheduler.process_scheduled_steps': {'queue': 'beat_tasks', 'routing_key': 'beat.process'},
        'workflow.tasks.operations.escalate.send_escalate_task': {'queue': 'high_priority', 'routing_key': 'high_priority', 'priority': 9},
        'workflow.tasks.operations.reminder.send_reminder_task': {'queue': 'default', 'routing_key': 'default', 'priority': 5},
    }

    # ---- Beat int√©gr√© (si tu gardes Beat ‚Äúunique‚Äù)
    celery_app.conf.beat_schedule = {
        'process-scheduled-steps-every-5min': {
            'task': 'workflow.tasks.core.scheduler.process_scheduled_steps',
            'schedule': timedelta(seconds=300),
            'options': {'queue': 'beat_tasks'}
        }
    }

    # ---- Contexte Flask pour toutes les tasks
    class FlaskContextTask(celery_app.Task):
        def __call__(self, *args, **kwargs):
            with flask_app.app_context():
                return super().__call__(*args, **kwargs)

        def on_failure(self, exc, task_id, args, kwargs, einfo):
            logger.error(f"Task {task_id} failed: {exc}")
            return super().on_failure(exc, task_id, args, kwargs, einfo)

    celery_app.Task = FlaskContextTask

    # ---- Signaux (logs)
    @worker_ready.connect
    def worker_ready_handler(sender, **kw):
        logger.info(f"Worker {sender.hostname} ready")

    @worker_shutdown.connect
    def worker_shutdown_handler(sender, **kw):
        logger.info(f"Worker {sender.hostname} shutting down")

    return celery_app


flask_app = create_app(Config)
celery_app = make_celery(flask_app)

@celery_app.task(bind=True)
def health_check(self):
    from datetime import datetime
    return {
        "status": "OK",
        "worker": self.request.hostname,
        "timestamp": datetime.utcnow().isoformat()
    }
```

> **Variante RedBeat (Beat distribu√©)** : ajoute simplement
>
> ```python
> celery_app.conf.beat_scheduler = 'redbeat.RedBeatScheduler'
> celery_app.conf.redbeat_redis_url = Config.CELERY_BROKER_URL
> ```
>
> et tu peux lancer plusieurs Beat en parall√®le.

---

# 2) `scheduler.py` ‚Äî idempotence + lock pessimiste (OK)

Ton approche `with_for_update(skip_locked=True)` est la bonne. Petite retouche ‚Äúdefensive‚Äù :

```python
# workflow/tasks/core/scheduler.py
from sqlalchemy.exc import SQLAlchemyError
from workflow.celery_app import celery_app as app
from api.models import FormContainer, WorkflowStep
from api.extensions import db
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

@app.task(bind=True)
def process_scheduled_steps(self) -> None:
    try:
        with db.session.begin():
            steps = (
                WorkflowStep.query
                .filter(
                    WorkflowStep.status == 'pending',
                    WorkflowStep.scheduled_time <= datetime.utcnow()
                )
                .with_for_update(skip_locked=True)
                .limit(100)
                .all()
            )

            for step in steps:
                container = FormContainer.query.get(step.container_id)
                if not container:
                    step.status = 'revoked'
                    continue

                # on marque processing TOUT DE SUITE, transaction ouverte
                step.status = 'processing'
                step.locked_at = datetime.utcnow()

                if step.step_type == 'reminder':
                    from workflow.tasks.operations.reminder import send_reminder_task
                    send_reminder_task.apply_async(args=[step.id, step.form_id, step.container_id, step.step_index])
                else:
                    from workflow.tasks.operations.escalate import send_escalate_task
                    send_escalate_task.apply_async(args=[step.id, step.form_id, step.container_id])

    except SQLAlchemyError as e:
        logger.error(f"Database error in step processing: {e}")
        db.session.rollback()
        self.retry(countdown=300)
    except Exception as e:
        logger.error(f"Unexpected error in step processing: {e}")
        self.retry(countdown=600)
```

---

# 3) `BaseWorkflowTask` ‚Äî corrections + verrous + retries propres

* Corrige l‚Äôusage de `step.query` (il faut la classe `WorkflowStep`).
* Marque `processing` sous la m√™me transaction avant de lancer le handler.
* Remonte correctement le statut/retries.

```python
# workflow/tasks/core/base.py
import logging
from functools import wraps
from typing import Dict, Callable
from datetime import datetime, timedelta
from celery import Task

from api.models import Form, FormContainer, WorkflowStep
from api.extensions import db
from sqlalchemy import select
from sqlalchemy.exc import SQLAlchemyError
from workflow.exceptions import RevokeChainRequested, WorkflowConfigurationError, WorkflowException

logger = logging.getLogger(__name__)

def workflow_task(max_retries: int = 3, retry_delay: int = 60):
    def decorator(func):
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            try:
                return func(self, *args, **kwargs)
            except RevokeChainRequested as e:
                logger.info(f"Chain revoked: {e}", extra=getattr(e, 'context', {}))
                return {'status': 'revoked', 'message': str(e)}
            except SQLAlchemyError as e:
                logger.error(f"Database error in {func.__name__}: {e}")
                self.retry(exc=e, countdown=retry_delay, max_retries=max_retries)
            except Exception as e:
                logger.error(f"Unexpected error in {func.__name__}: {e}")
                self.retry(exc=e, countdown=retry_delay, max_retries=max_retries)
        return wrapper
    return decorator


class BaseWorkflowTask(Task):
    autoretry_for = (Exception,)
    max_retries = 3
    retry_backoff = True
    retry_backoff_max = 600
    rate_limit = '10/m'

    def _handle_task(self, step_id: str, context: Dict, handler: Callable) -> Dict:
        # Lock pessimiste + marquage "processing" atomique
        with db.session.begin():
            step = db.session.execute(
                select(WorkflowStep)
                .where(WorkflowStep.id == step_id)
                .with_for_update(skip_locked=True)
            ).scalar_one_or_none()

            if not step:
                raise RevokeChainRequested("Step not found or locked")

            context.update({'step_id': step_id, 'task_id': self.request.id})

            self._validate_prerequisites(step, context)

            if step.status not in ('processing', 'pending'):
                raise WorkflowException(
                    f"Invalid step state: {step.status}",
                    {'current_status': step.status, **context}
                )

            # si le scheduler a d√©j√† mis processing, on continue,
            # sinon on le met maintenant (cas d‚Äôappel direct)
            if step.status == 'pending':
                step.status = 'processing'
                step.locked_at = datetime.utcnow()

        try:
            result = handler(context)
            self._finalize_step(step_id, 'completed')
            return result
        except RevokeChainRequested as e:
            self._handle_revocation(step_id, context, e)
            return getattr(e, "return_value", {"status": "revoked", "message": str(e)})
        except Exception as e:
            self._handle_retry(step_id, e)
            raise

    def _validate_prerequisites(self, step: WorkflowStep, context: Dict) -> None:
        form = Form.query.get(context['form_id'])
        container = FormContainer.query.get(context['container_id'])
        if not form or not container:
            raise RevokeChainRequested("Form or container missing", {'status': 'revoked', **context})

    def _finalize_step(self, step_id: str, status: str) -> None:
        with db.session.begin():
            step = db.session.get(WorkflowStep, step_id)
            if step:
                step.status = status

    def _handle_revocation(self, step_id: str, context: Dict, error: RevokeChainRequested) -> None:
        with db.session.begin():
            step = db.session.get(WorkflowStep, step_id)
            if step:
                logger.warning(f"Revoking workflow chain: {error}", extra=context)
                # on r√©voque uniquement ce step :
                step.status = 'revoked'

    def _handle_retry(self, step_id: str, error: Exception) -> None:
        with db.session.begin():
            step = db.session.get(WorkflowStep, step_id)
            if step:
                step.retries += 1
                if step.retries >= step.max_retries:
                    step.status = 'failed'
                else:
                    step.status = 'pending'
                    step.scheduled_time = datetime.utcnow() + timedelta(hours=1)
```

---

# 4) **Fix des tasks ‚Äúoperations‚Äù** ‚Äî bugs concrets

Tu as deux bugs qui provoqueront des erreurs + des emails non conformes :

* Typos/propri√©t√©s : `appication` ‚Üí `application`.
* Appel de `MailManager.send_email(...)` **mauvais ordre/arguments**.
  Ta signature est :

  ```python
  def send_email(form_container, template_type, recipient_email=None, cc_emails=None,
                 substitutions=None, workflow_step='start'):
  ```

  ‚Üí Il faut lui passer **`form_container=`** et **`template_type=`**, pas `mail_sender`/`subject`/`token` en positions.

### `escalate.py` (corrig√©)

```python
# workflow/tasks/operations/escalate.py
import logging
from typing import Dict
from datetime import datetime
from api.models import FormContainer
from api.helpers.tools import log_timeline_event
from workflow.emails.email_manager import MailManager
from workflow.celery_app import celery_app as app
from workflow.tasks.core.base import BaseWorkflowTask, workflow_task

logger = logging.getLogger(__name__)

@app.task(base=BaseWorkflowTask, bind=True)
@workflow_task()
def send_escalate_task(self, step_id: str, form_id: str, container_id: str) -> Dict:
    def task_handler(context: Dict) -> Dict:
        form_container: FormContainer = FormContainer.query.get(context['container_id'])

        # envoi via template "escalate"
        MailManager.send_email(
            form_container=form_container,
            template_type='escalate',
            recipient_email=form_container.escalade_email,
            cc_emails=form_container.cc_emails,
            substitutions={'workflow_reason': 'Escalation Required'},
            workflow_step='escalate'
        )

        log_timeline_event(
            form_container,
            form_id,
            datetime.utcnow(),
            "Escalation triggered",
            'escalate'
        )
        return {'status': 'success', 'escalation': True}

    return self._handle_task(step_id, {
        'form_id': form_id,
        'container_id': container_id
    }, task_handler)
```

### `reminder.py` (corrig√©)

```python
# workflow/tasks/operations/reminder.py
import logging
from typing import Dict
from datetime import datetime
from api.models import FormContainer
from api.helpers.tools import log_timeline_event
from workflow.emails.email_manager import MailManager
from workflow.celery_app import celery_app as app
from workflow.tasks.core.base import BaseWorkflowTask, workflow_task

logger = logging.getLogger(__name__)

@app.task(base=BaseWorkflowTask, bind=True)
@workflow_task()
def send_reminder_task(self, step_id: str, form_id: str, container_id: str, reminder_count: int) -> Dict:
    def task_handler(context: Dict) -> Dict:
        form_container: FormContainer = FormContainer.query.get(context['container_id'])

        MailManager.send_email(
            form_container=form_container,
            template_type='reminder',
            recipient_email=form_container.user_email,
            cc_emails=form_container.cc_emails,
            substitutions={'reminder_count': reminder_count},
            workflow_step='reminder'
        )

        log_timeline_event(
            form_container,
            form_id,
            datetime.utcnow(),
            f"Reminder {reminder_count} sent",
            'reminder'
        )
        return {'status': 'success', 'reminder_count': reminder_count}

    return self._handle_task(step_id, {
        'form_id': form_id,
        'container_id': container_id,
        'reminder_count': reminder_count
    }, task_handler)
```

---

# 5) `email_manager.py` ‚Äî OK mais deux micro-am√©liorations

* S√©cu : transforme `to`/`cc` en listes filtr√©es (non-vides).
* Fail-fast si aucun destinataire.

```python
# workflow/emails/email_manager.py (ajouts mineurs)
# ... (le reste inchang√©)

        to = (recipient_email or form_container.user_email) or ""
        cc = cc_emails or form_container.cc_emails or []

        recipients = [to] if isinstance(to, str) and to.strip() else list(filter(None, to or []))
        cc_list = list({e for e in (cc or []) if e})

        if not recipients:
            raise ValueError("No recipient email resolved")

        msg = Message(
            subject=subject,
            sender=mail_sender,
            recipients=recipients,
            cc=cc_list
        )
        msg.html = full_html
        mail.send(msg)
```

---

# 6) PostgreSQL ‚Äî r√©glages runtime recommand√©s

Dans `SQLALCHEMY_ENGINE_OPTIONS` (tu l‚Äôas d√©j√† bien amorc√©) :

```python
SQLALCHEMY_ENGINE_OPTIONS = {
    'pool_size': 20,
    'max_overflow': 30,
    'pool_pre_ping': True,
    'pool_recycle': 3600,
    # Optionnel : isolation plus stricte si besoin
    # 'isolation_level': 'READ COMMITTED',  # d√©faut PG
}
```

Et c√¥t√© PostgreSQL (param√®tres serveur) :

* `deadlock_timeout = '1s'`
* `lock_timeout = '5s'` (si tu veux fail-fast sur locks)
* Index utiles sur `(status, scheduled_time)` de `WorkflowStep`.

---

# 7) D√©ploiement

* **Workers (N‚â•2)**, **un seul Beat** (ou **RedBeat** si tu veux N Beats).
* Backends Flask derri√®re LB.
* DB **master/replica** (√©critures sur master).
* Redis/RabbitMQ HA (sentinels/cluster).

---

Si tu veux, je te pr√©pare un **diff pr√™t √† coller** (patch unified) pour tes fichiers actuels, ou un **docker-compose** minimal ‚Äúprod-like‚Äù (web + worker x2 + beat + postgres + redis + nginx).






Parfait üëç tu veux une archi **multi-serveurs (actif-actif)** avec :

* **2 serveurs** (ou +) o√π tournent tes workers **et** Beat,
* **un Redis global en cluster** (ou en Sentinel) qui sert √† la fois de broker, backend, et scheduler distribu√© via **RedBeat**.

Dans ce cas, tout ton code peut rester le m√™me √† une exception pr√®s : **`celery_app.py` doit √™tre configur√© pour RedBeat + Redis cluster**.

---

## üîπ `workflow/celery_app.py` ‚Äì version actif-actif multi-serveurs

```python
from datetime import timedelta, datetime
import logging
from celery import Celery
from kombu import Queue, Exchange
from celery.signals import worker_ready, worker_shutdown
from config import Config
from api.app import create_app

logger = logging.getLogger(__name__)

def make_celery(flask_app):
    celery_app = Celery(
        __name__,
        broker=Config.CELERY_BROKER_URL,        # Redis cluster ou Sentinel
        backend=Config.CELERY_RESULT_BACKEND,  # Redis aussi
        enable_utc=True,
    )

    # -------------------------
    #  Configuration global HA
    # -------------------------
    celery_app.conf.update(
        task_acks_late=True,
        worker_prefetch_multiplier=1,
        broker_connection_retry_on_startup=True,
        broker_connection_retry=True,
        broker_connection_max_retries=100,
        task_serializer='json',
        result_serializer='json',
        accept_content=['json'],
        result_expires=timedelta(hours=6),
        worker_send_task_events=True,
        task_send_sent_event=True,
    )

    # -------------------------
    #  RedBeat (Beat distribu√©)
    # -------------------------
    celery_app.conf.beat_scheduler = 'redbeat.RedBeatScheduler'
    celery_app.conf.redbeat_redis_url = Config.CELERY_BROKER_URL
    celery_app.conf.redbeat_lock_key = 'redbeat:lock'
    celery_app.conf.redbeat_key_prefix = 'redbeat:'

    celery_app.conf.beat_schedule = {
        'process-scheduled-steps': {
            'task': 'workflow.tasks.core.scheduler.process_scheduled_steps',
            'schedule': timedelta(seconds=300),
            'options': {'queue': 'beat_tasks'}
        }
    }

    # -------------------------
    #  Queues d√©di√©es
    # -------------------------
    default_ex = Exchange('default', type='direct')
    beat_ex = Exchange('beat', type='direct')
    high_ex = Exchange('high_priority', type='direct')

    celery_app.conf.task_queues = (
        Queue('high_priority', high_ex, routing_key='high_priority',
              queue_arguments={'x-max-priority': 10}),
        Queue('beat_tasks', beat_ex, routing_key='beat.process'),
        Queue('default', default_ex, routing_key='default'),
    )

    celery_app.conf.task_default_queue = 'default'
    celery_app.conf.task_routes = {
        'workflow.tasks.core.scheduler.process_scheduled_steps': {'queue': 'beat_tasks'},
        'workflow.tasks.operations.escalate.send_escalate_task': {'queue': 'high_priority'},
        'workflow.tasks.operations.reminder.send_reminder_task': {'queue': 'default'},
    }

    # -------------------------
    #  Contexte Flask
    # -------------------------
    class FlaskContextTask(celery_app.Task):
        def __call__(self, *args, **kwargs):
            with flask_app.app_context():
                return super().__call__(*args, **kwargs)

        def on_failure(self, exc, task_id, args, kwargs, einfo):
            logger.error(f"Task {task_id} failed: {exc}")
            return super().on_failure(exc, task_id, args, kwargs, einfo)

    celery_app.Task = FlaskContextTask

    # -------------------------
    #  Signaux log
    # -------------------------
    @worker_ready.connect
    def worker_ready_handler(sender, **kw):
        logger.info(f"Worker {sender.hostname} ready")

    @worker_shutdown.connect
    def worker_shutdown_handler(sender, **kw):
        logger.info(f"Worker {sender.hostname} shutting down")

    return celery_app


flask_app = create_app(Config)
celery_app = make_celery(flask_app)

@celery_app.task(bind=True)
def health_check(self):
    return {
        "status": "OK",
        "worker": self.request.hostname,
        "timestamp": datetime.utcnow().isoformat()
    }
```

---

## üîπ  D√©ploiement sur 2 serveurs (actif-actif)

üëâ Tu lances **les m√™mes process sur les 2 machines** :

```bash
# Sur les 2 serveurs
celery -A workflow.celery_app.celery_app worker -Q default,high_priority,beat_tasks -l INFO -n worker@%h
celery -A workflow.celery_app.celery_app beat -l INFO -s /tmp/celerybeat-schedule
```

* Gr√¢ce √† **RedBeat**, les 2 Beat vont se coordonner ‚Üí un seul ex√©cute le job toutes les 5 min, l‚Äôautre est standby.
* Gr√¢ce √† Redis cluster, si un n≈ìud tombe, tout continue.
* Les workers consomment en parall√®le sans doublons (gr√¢ce √† `with_for_update(skip_locked)` dans tes tasks DB).

---

## üîπ Avantages

‚úÖ **Pas de SPOF Beat** ‚Üí tu peux lancer un Beat sur chaque serveur.
‚úÖ **Redis cluster global** ‚Üí broker + backend + Beat distribu√©, robuste.
‚úÖ **Workers scalables** ‚Üí chaque serveur peut en h√©berger plusieurs.
‚úÖ **DB s√ªre** ‚Üí `skip_locked` √©vite les doublons.

---

Veux-tu que je te pr√©pare un **docker-compose multi-nodes** (2 serveurs simul√©s, 1 Redis cluster, Celery workers + Beat) pour que tu testes l‚Äôarchi avant de passer en infra r√©elle ?
